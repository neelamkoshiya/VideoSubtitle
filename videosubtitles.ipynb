{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Subtitles in Spanish\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Architecture\n",
    "\n",
    "In this example, we will use the Notebooks feature of Amazon SageMaker to create an interactive notebook with Python code. These notebooks are just one part of Amazon SageMaker, a fully-managed service that covers the entire machine learning workflow to label and prepare your data, choose an algorithm, train the algorithm, tune and optimize it for deployment, make predictions, and take action. In this example though, for the actual machine learning and prediction, we will be using Amazon transcribe to extract text/subtitle from the video and Amazon Translate to help us to translate the subtitle into spanish. All of our input video files will be read from a bucket in Amazon Simple Storage Service (Amazon S3), an object storage service that offers industry-leading scalability, data availability, security, and performance. The SRT file which has the subtitle is written to the S3 bucket. This notebook is just for the demo purpose and eventually for the production workload, you can split this code in different lambda and use step function to orchestrate. You can combine the video and srt file to create a video with appropriate subtitles\n",
    "\n",
    "![alt-text](VideoSubtitles.jpg \"diagram\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#Import all of the required libraries\n",
    "%matplotlib inline\n",
    "import boto3\n",
    "import json\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from imageio import imread\n",
    "from datetime import datetime\n",
    "import base64\n",
    "import time\n",
    "#import cStringIO\n",
    "\n",
    "\n",
    "\n",
    "#Implement AWS Services\n",
    "transcribe=boto3.client('transcribe')\n",
    "translate = boto3.client(service_name='translate')\n",
    "s3=boto3.resource('s3')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TranscriptionJob': {'TranscriptionJobName': 'Example-job181120221425',\n",
       "  'TranscriptionJobStatus': 'IN_PROGRESS',\n",
       "  'LanguageCode': 'en-US',\n",
       "  'MediaFormat': 'mp4',\n",
       "  'Media': {'MediaFileUri': 's3://nkkoshiy-demobucket/VideoSubtitles/reinvent.mp4'},\n",
       "  'StartTime': datetime.datetime(2020, 11, 18, 22, 14, 26, 69000, tzinfo=tzlocal()),\n",
       "  'CreationTime': datetime.datetime(2020, 11, 18, 22, 14, 26, 29000, tzinfo=tzlocal())},\n",
       " 'ResponseMetadata': {'RequestId': '86e49a8a-8e63-442a-a05a-193c9aa2621e',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Wed, 18 Nov 2020 22:14:26 GMT',\n",
       "   'x-amzn-requestid': '86e49a8a-8e63-442a-a05a-193c9aa2621e',\n",
       "   'content-length': '294',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_uri = 's3://nkkoshiy-demobucket/VideoSubtitles/reinvent.mp4'\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%d%m%y%H%M%S\")\n",
    "job_name='Example-job'+current_time\n",
    "transcribe.start_transcription_job(\n",
    "        TranscriptionJobName=job_name,\n",
    "        Media={'MediaFileUri': file_uri},\n",
    "        MediaFormat='mp4',\n",
    "        LanguageCode='en-US',\n",
    "        OutputBucketName='nkkoshiy-demobucket',\n",
    "        OutputKey=job_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for Example-job181120221425. Current status is IN_PROGRESS.\n",
      "Waiting for Example-job181120221425. Current status is IN_PROGRESS.\n",
      "Waiting for Example-job181120221425. Current status is IN_PROGRESS.\n",
      "Waiting for Example-job181120221425. Current status is IN_PROGRESS.\n",
      "Waiting for Example-job181120221425. Current status is IN_PROGRESS.\n",
      "Waiting for Example-job181120221425. Current status is IN_PROGRESS.\n",
      "Waiting for Example-job181120221425. Current status is IN_PROGRESS.\n",
      "Job Example-job181120221425 is COMPLETED.\n",
      "Download the transcript from\n",
      "\thttps://s3.us-east-1.amazonaws.com/nkkoshiy-demobucket/Example-job181120221425.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    max_tries = 60\n",
    "    while max_tries > 0:\n",
    "        max_tries -= 1\n",
    "        job = transcribe.get_transcription_job(TranscriptionJobName=job_name)\n",
    "        job_status = job['TranscriptionJob']['TranscriptionJobStatus']\n",
    "        if job_status in ['COMPLETED', 'FAILED']:\n",
    "            print(f\"Job {job_name} is {job_status}.\")\n",
    "            if job_status == 'COMPLETED':\n",
    "                print(\n",
    "                    f\"Download the transcript from\\n\"\n",
    "                    f\"\\t{job['TranscriptionJob']['Transcript']['TranscriptFileUri']}.\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Waiting for {job_name}. Current status is {job_status}.\")\n",
    "        time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucketname='nkkoshiy-demobucket'\n",
    "obj = s3.Object(bucketname, job_name)\n",
    "body = obj.get()['Body'].read()\n",
    "json_content = json.loads(body)\n",
    "SampleText=\"Hello, how are you?\"\n",
    "translate = boto3.client(service_name='translate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '2C0DD46F211501A1',\n",
       "  'HostId': 'upg87WWEr5U7i0AnlKb+anqntP3S5E0mqEg4Dbd6KckyZ+62uXVtf1pUwlu5110hHaGWhCGsLfY=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'upg87WWEr5U7i0AnlKb+anqntP3S5E0mqEg4Dbd6KckyZ+62uXVtf1pUwlu5110hHaGWhCGsLfY=',\n",
       "   'x-amz-request-id': '2C0DD46F211501A1',\n",
       "   'date': 'Wed, 18 Nov 2020 22:17:46 GMT',\n",
       "   'etag': '\"4724901463bc94abcadc2ae98c1cadb0\"',\n",
       "   'content-length': '0',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"4724901463bc94abcadc2ae98c1cadb0\"'}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucketname='nkkoshiy-demobucket'\n",
    "obj = s3.Object(bucketname, job_name)\n",
    "body = obj.get()['Body'].read()\n",
    "json_content = json.loads(body)\n",
    "#print(json_content['results'])\n",
    "i=0\n",
    "\n",
    "for index,content in enumerate(json_content['results']['items']):\n",
    "    #print(content)\n",
    "    #currentvalue=content['alternatives'][0]['content']\n",
    "    #print(currentvalue)\n",
    "    result = translate.translate_text(Text=content['alternatives'][0]['content'], SourceLanguageCode=\"en\", TargetLanguageCode=\"es\")\n",
    "    #newvalue=result['TranslatedText']\n",
    "    #print(newvalue)\n",
    "    #json.loads(json.dumps(json_content).replace(currentvalue,newvalue))\n",
    "    #print(json_content)\n",
    "    #print(\"****\")\n",
    "    #print(result['TranslatedText'])\n",
    "    #print(\"#####\")\n",
    "    json_content['results']['items'][index]['alternatives'][0]['content']=result['TranslatedText']\n",
    "    #print(content['alternatives'][0]['content'])\n",
    "    #spanishtext= str(i)+'\\n'+content['start_time']+\"-->\"+content['end_time']+'\\n'+result['TranslatedText']\n",
    "#print(json_content['results']) \n",
    "result1 = translate.translate_text(Text=json_content['results']['transcripts'][0]['transcript'], SourceLanguageCode=\"en\", TargetLanguageCode=\"es\")\n",
    "#currentvalue=json_content['results']['transcripts'][0]['transcript']\n",
    "#newvalue=result1['TranslatedText']\n",
    "#json.loads(json.dumps(json_content).replace(currentvalue,newvalue))\n",
    "json_content['results']['transcripts'][0]['transcript']=result1\n",
    "#print(\"Result****\")\n",
    "#print(result['TranslatedText']) \n",
    "#print(\"Result1****###\")\n",
    "#print(result1['TranslatedText']) \n",
    "#print(json_content['results'])\n",
    "translatedfilename=\"spanish\"+job_name\n",
    "s3object = s3.Object(bucketname, translatedfilename)\n",
    "\n",
    "s3object.put(Body=(bytes(json.dumps(json_content).encode('UTF-8'))))\n",
    "#print(json_content)\n",
    "\n",
    "#print(json_content['results']['transcripts'][0]['transcript'])\n",
    "#print(json_content['results']['items'][1]['alternatives'][0]['content'])\n",
    "#print(json_content['results']['items'][2]['alternatives'][0]['content'])\n",
    "#print(json_content['results']['items'][3]['alternatives'][0]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimeCode( seconds ):\n",
    "# Format and return a string that contains the converted number of seconds into SRT format\n",
    "\n",
    "   thund = int(seconds % 1 * 1000)\n",
    "   tseconds = int( seconds )\n",
    "   tsecs = ((float( tseconds) / 60) % 1) * 60\n",
    "   tmins = int( tseconds / 60 )\n",
    "   return str( \"%02d:%02d:%02d,%03d\" % (00, tmins, int(tsecs), thund ))\n",
    "def newPhrase():\n",
    "\treturn { 'start_time': '', 'end_time': '', 'words' : [] }\n",
    "def getPhraseText( phrase ):\n",
    "\n",
    "\tlength = len(phrase[\"words\"])\n",
    "\t\t\n",
    "\tout = \"\"\n",
    "\tfor i in range( 0, length ):\n",
    "\t\tif re.match( '[a-zA-Z0-9]', phrase[\"words\"][i]):\n",
    "\t\t\tif i > 0:\n",
    "\t\t\t\tout += \" \" + phrase[\"words\"][i]\n",
    "\t\t\telse:\n",
    "\t\t\t\tout += phrase[\"words\"][i]\n",
    "\t\telse:\n",
    "\t\t\tout += phrase[\"words\"][i]\n",
    "\t\t\t\n",
    "\treturn out\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Creating phrases from transcript...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "items = json_content['results']['items']\n",
    "    \n",
    "    #set up some variables for the first pass\n",
    "phrase =  newPhrase()\n",
    "phrases = []\n",
    "nPhrase = True\n",
    "x = 0\n",
    "c = 0\n",
    "\n",
    "print (\"==> Creating phrases from transcript...\")\n",
    "\n",
    "for item in items:\n",
    "\n",
    "        # if it is a new phrase, then get the start_time of the first item\n",
    "    if nPhrase == True:\n",
    "        if item[\"type\"] == \"pronunciation\":\n",
    "            phrase[\"start_time\"] = getTimeCode( float(item[\"start_time\"]) )\n",
    "            nPhrase = False\n",
    "        c+= 1\n",
    "    else:    \n",
    "            # We need to determine if this pronunciation or puncuation here\n",
    "            # Punctuation doesn't contain timing information, so we'll want\n",
    "            # to set the end_time to whatever the last word in the phrase is.\n",
    "            # Since we are reading through each word sequentially, we'll set \n",
    "            # the end_time if it is a word\n",
    "        if item[\"type\"] == \"pronunciation\":\n",
    "            phrase[\"end_time\"] = getTimeCode( float(item[\"end_time\"]) )\n",
    "                \n",
    "        # in either case, append the word to the phrase...\n",
    "    phrase[\"words\"].append(item['alternatives'][0][\"content\"])\n",
    "    x += 1\n",
    "        \n",
    "        # now add the phrase to the phrases, generate a new phrase, etc.\n",
    "    if x == 10:\n",
    "            #print c, phrase\n",
    "        phrases.append(phrase)\n",
    "        phrase = newPhrase()\n",
    "        nPhrase = True\n",
    "        x = 0\n",
    "#print(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '37B3C2EFEB1163D5',\n",
       "  'HostId': '0krG4BvAhisGR2i2EKueOdGb5OPbz2dxvopmDIIxuxm+Pi9RDIO8WJrD/Y0VWuzFJz+CkWLqNcg=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': '0krG4BvAhisGR2i2EKueOdGb5OPbz2dxvopmDIIxuxm+Pi9RDIO8WJrD/Y0VWuzFJz+CkWLqNcg=',\n",
       "   'x-amz-request-id': '37B3C2EFEB1163D5',\n",
       "   'date': 'Wed, 18 Nov 2020 22:19:13 GMT',\n",
       "   'etag': '\"d05064a20694d70df5e3323d03baf545\"',\n",
       "   'content-length': '0',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"d05064a20694d70df5e3323d03baf545\"'}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import codecs\n",
    "import re\n",
    "filename=job_name+\"SRTFile.srt\"\n",
    "e = codecs.open(filename,\"w+\", \"utf-8\")\n",
    "x = 1\n",
    "\t\n",
    "for phrase in phrases:\n",
    "\n",
    "\t\t# determine how many words are in the phrase\n",
    "\tlength = len(phrase[\"words\"])\n",
    "\t\t\n",
    "\t\t# write out the phrase number\n",
    "\te.write( str(x) + \"\\n\" )\n",
    "\tx += 1\n",
    "\t\t\n",
    "\t\t# write out the start and end time\n",
    "\te.write( phrase[\"start_time\"] + \" --> \" + phrase[\"end_time\"] + \"\\n\" )\n",
    "\t\t\t\t\t\n",
    "\t\t# write out the full phase.  Use spacing if it is a word, or punctuation without spacing\n",
    "\tout = getPhraseText( phrase )\n",
    "\n",
    "\t\t# write out the srt file\n",
    "\te.write(out + \"\\n\\n\" )\n",
    "\t\t\n",
    "\n",
    "\t\t#print out\n",
    "\t\t\n",
    "e.close()\n",
    "with codecs.open(filename, 'rb', encoding='utf-8') as fin:\n",
    "    text = fin.read()\n",
    "s3.Object(bucketname, filename).put(Body=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
